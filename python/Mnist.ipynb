{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "import keras\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "\n",
    "mnist_dir = '/Users/matt/dev/machine-learning/datasets/mnist/'\n",
    "\n",
    "path_test_labels = os.path.join(mnist_dir, 't10k-labels-idx1-ubyte')\n",
    "path_test_images = os.path.join(mnist_dir, 't10k-images-idx3-ubyte')\n",
    "path_train_labels = os.path.join(mnist_dir, 'train-labels-idx1-ubyte')\n",
    "path_train_images = os.path.join(mnist_dir, 'train-images-idx3-ubyte')\n",
    "\n",
    "class Mnist:\n",
    "    def __init__(self, labels_path, images_path):\n",
    "        with open(labels_path, 'rb') as file:\n",
    "            magic, num = struct.unpack(\">II\", file.read(8))\n",
    "            assert magic == 2049\n",
    "            self.labels = np.fromfile(file, dtype=np.int8)\n",
    "\n",
    "        with open(images_path, 'rb') as file:\n",
    "            magic, num, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            assert magic == 2051\n",
    "            raw_images = np.fromfile(file, dtype=np.uint8)\n",
    "            self.images = raw_images.reshape(num, rows, cols) # Nx28x28\n",
    "            # raw = np.fromfile(file, dtype=np.int8)\n",
    "            # print(raw.shape)\n",
    "            # print(raw.reshape(num, rows, cols).shape)\n",
    "\n",
    "    def flattened_images(self):\n",
    "        (num_images, rows, cols) = self.images.shape\n",
    "        flattened = self.images.reshape(num_images, rows*cols) # Nx784\n",
    "        return self._normalize(flattened)\n",
    "\n",
    "    def one_hot_labels(self):\n",
    "        return np_utils.to_categorical(self.labels, 10)\n",
    "\n",
    "    def _normalize(self, nparray):\n",
    "        nparray = nparray.astype('float32')\n",
    "        nparray /= 255\n",
    "        return nparray\n",
    "\n",
    "train = Mnist(path_train_labels, path_train_images)\n",
    "test = Mnist(path_test_labels, path_test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.2424 - acc: 0.9247 - val_loss: 0.0981 - val_acc: 0.9691\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.1013 - acc: 0.9696 - val_loss: 0.0828 - val_acc: 0.9758\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.0747 - acc: 0.9777 - val_loss: 0.0870 - val_acc: 0.9745\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.0598 - acc: 0.9819 - val_loss: 0.0672 - val_acc: 0.9802\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.0500 - acc: 0.9850 - val_loss: 0.0722 - val_acc: 0.9812\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.0436 - acc: 0.9867 - val_loss: 0.0758 - val_acc: 0.9821\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.0386 - acc: 0.9886 - val_loss: 0.0783 - val_acc: 0.9816\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.0361 - acc: 0.9898 - val_loss: 0.0817 - val_acc: 0.9820\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.0322 - acc: 0.9905 - val_loss: 0.0822 - val_acc: 0.9815\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.0297 - acc: 0.9902 - val_loss: 0.0807 - val_acc: 0.9836\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.0271 - acc: 0.9924 - val_loss: 0.0874 - val_acc: 0.9824\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 11s - loss: 0.0268 - acc: 0.9925 - val_loss: 0.0939 - val_acc: 0.9825\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 11s - loss: 0.0237 - acc: 0.9935 - val_loss: 0.1053 - val_acc: 0.9826\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 11s - loss: 0.0237 - acc: 0.9935 - val_loss: 0.0986 - val_acc: 0.9821\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 11s - loss: 0.0216 - acc: 0.9941 - val_loss: 0.0991 - val_acc: 0.9837\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 11s - loss: 0.0210 - acc: 0.9945 - val_loss: 0.1034 - val_acc: 0.9838\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 11s - loss: 0.0212 - acc: 0.9944 - val_loss: 0.0991 - val_acc: 0.9834\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 11s - loss: 0.0183 - acc: 0.9948 - val_loss: 0.1120 - val_acc: 0.9829\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 11s - loss: 0.0193 - acc: 0.9954 - val_loss: 0.1167 - val_acc: 0.9836\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 11s - loss: 0.0190 - acc: 0.9948 - val_loss: 0.1164 - val_acc: 0.9814\n",
      "('Test score:', 0.11637635516840407)\n",
      "('Test accuracy:', 0.98140000000000005)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "nb_epoch = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=(784)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train.flattened_images(),\n",
    "                    train.one_hot_labels(),\n",
    "                    batch_size=batch_size,\n",
    "                    nb_epoch=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test.flattened_images(),\n",
    "                                     test.one_hot_labels()))\n",
    "score = model.evaluate(test.flattened_images(),\n",
    "                      test.one_hot_labels(),\n",
    "                      verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "name": "Mnist.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
